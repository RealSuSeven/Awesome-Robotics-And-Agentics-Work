# Robotics Paper
## Foundation Model Based Robotics
- **Eureka: Human-Level Reward Design via Coding Large Language Models** <br>
  *Yecheng Jason Ma, William Liang, Guanzhi Wang, De-An Huang, Osbert Bastani, Dinesh Jayaraman, Yuke Zhu, Linxi Fan, Anima Anandkumar* <br>
  arXiv, 2023.10 [[Paper](https://arxiv.org/abs/2310.12931)] <br>
  [[Code](https://github.com/eureka-research/Eureka)] ![](https://img.shields.io/github/stars/eureka-research/Eureka?style=round-square&logo=Github&logoColor=white) ![](https://img.shields.io/github/last-commit/eureka-research/Eureka?style=round-square&logo=Github&logoColor=white)
- **Toward General-Purpose Robots via Foundation Models: A Survey and Meta-Analysis** `Survey`<br>
  *Yafei Hu, Quanting Xie, Vidhi Jain, Jonathan Francis, Jay Patrikar, Nikhil Keetha, Seungchan Kim, Yaqi Xie, Tianyi Zhang, Zhibo Zhao, Yu-Quan Chong, Chen Wang, Katia Sycara, Matthew Johnson-Roberson, Dhruv Batra, Xiaolong Wang, Sebastian Scherer, Zsolt Kira, Fei Xia, Yonatan Bisk* <br>
  arXiv, 2023.12 [[Paper](https://arxiv.org/abs/2312.08782)] <br>
  [[Code](https://github.com/JeffreyYH/robotics-fm-survey)] ![](https://img.shields.io/github/stars/JeffreyYH/robotics-fm-survey?style=round-square&logo=Github&logoColor=white) ![](https://img.shields.io/github/last-commit/JeffreyYH/robotics-fm-survey?style=round-square&logo=Github&logoColor=white)
- **Foundation Models in Robotics: Applications, Challenges, and the Future** `Survey`<br>
  *Roya Firoozi, Johnathan Tucker, Stephen Tian, Anirudha Majumdar, Jiankai Sun, Weiyu Liu, Yuke Zhu, Shuran Song, Ashish Kapoor, Karol Hausman, Brian Ichter, Danny Driess, Jiajun Wu, Cewu Lu, Mac Schwager* <br>
  arXiv, 2023.12 [[Paper](https://arxiv.org/abs/2312.07843)] <br>
  [[Code](https://github.com/robotics-survey/Awesome-Robotics-Foundation-Models)] ![](https://img.shields.io/github/stars/robotics-survey/Awesome-Robotics-Foundation-Models?style=round-square&logo=Github&logoColor=white) ![](https://img.shields.io/github/last-commit/robotics-survey/Awesome-Robotics-Foundation-Models?style=round-square&logo=Github&logoColor=white)
- **RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning via Generative Simulation** <br>
  *Yufei Wang, Zhou Xian, Feng Chen, Tsun-Hsuan Wang, Yian Wang, Zackory Erickson, David Held, Chuang Gan* <br>
  arXiv, 2023.11 [[Paper](https://arxiv.org/abs/2311.01455)] <br>
  [[Code](https://github.com/Genesis-Embodied-AI/RoboGen)] ![](https://img.shields.io/github/stars/Genesis-Embodied-AI/RoboGen?style=round-square&logo=Github&logoColor=white) ![](https://img.shields.io/github/last-commit/Genesis-Embodied-AI/RoboGen?style=round-square&logo=Github&logoColor=white)
- **GenSim: Generating Robotic Simulation Tasks via Large Language Models** <br>
  *Lirui Wang, Yiyang Ling, Zhecheng Yuan, Mohit Shridhar, Chen Bao, Yuzhe Qin, Bailin Wang, Huazhe Xu, Xiaolong Wang* <br>
  arXiv, 2023.10 [[Paper](https://arxiv.org/abs/2310.01361)] <br>
  [[Code](https://github.com/liruiw/GenSim)] ![](https://img.shields.io/github/stars/liruiw/GenSim?style=round-square&logo=Github&logoColor=white) ![](https://img.shields.io/github/last-commit/liruiw/GenSim?style=round-square&logo=Github&logoColor=white)
- **VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models** <br>
  Team: Stanford University, Fei-Fei Li. <br>
  *Wenlong Huang, Chen Wang, Ruohan Zhang, Yunzhu Li, Jiajun Wu, Li Fei-Fei* <br>
  **CoRL'23**, arXiv, 2023.10 [[Paper](https://arxiv.org/abs/2307.05973)] <br>
  [[Code](https://github.com/huangwl18/VoxPoser)] ![](https://img.shields.io/github/stars/huangwl18/VoxPoser?style=round-square&logo=Github&logoColor=white) ![](https://img.shields.io/github/last-commit/huangwl18/VoxPoser?style=round-square&logo=Github&logoColor=white)
- **RVT: Robotic View Transformer for 3D Object Manipulation** <br>
  Team: NVIDIA Labs <br>
  *Ankit Goyal, Jie Xu, Yijie Guo, Valts Blukis, Yu-Wei Chao, Dieter Fox* <br>
  **CoRL (Oral)**, arXiv, 2023.06 [[Paper](https://arxiv.org/abs/2307.05973)] <br>
  [[Code](https://github.com/nvlabs/rvt)] ![](https://img.shields.io/github/stars/nvlabs/rvt?style=round-square&logo=Github&logoColor=white) ![](https://img.shields.io/github/last-commit/nvlabs/rvt?style=round-square&logo=Github&logoColor=white)
- **Distilled Feature Fields Enable Few-Shot Language-Guided Manipulation** <br>
  Team: NVIDIA Labs <br>
  *William Shen, Ge Yang, Alan Yu, Jansen Wong, Leslie Pack Kaelbling, Phillip Isola* <br>
  **CoRL'23 (Best Paper)**, arXiv, 2023.06 [[Paper](https://arxiv.org/abs/2308.07931)], [[Code](https://github.com/f3rm/f3rm)] ![](https://img.shields.io/github/stars/f3rm/f3rm?style=round-square&logo=Github&logoColor=white) ![](https://img.shields.io/github/last-commit/f3rm/f3rm?style=round-square&logo=Github&logoColor=white)